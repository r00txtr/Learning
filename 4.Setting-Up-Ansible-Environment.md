# Setting Up Ansible Environment: Control and Managed Nodes

Ansible simplifies IT automation by providing a platform where you can manage multiple systems from a single machine, called the **control node**, while the systems being managed are called **managed nodes**. This article provides a step-by-step guide for setting up the Ansible environment by preparing control and managed nodes and installing Ansible on the control node.

## Table of Contents
1. **Understanding Control and Managed Nodes**
2. **Preparing the Environment**
   - Setting Up Hosts File
   - Testing Connectivity Between Nodes
   - Configuring SSH Key-Based Authentication
3. **Installing Ansible on the Control Node**
4. **Configuring Ansible Inventory**
5. **Testing the Setup**
6. **Summary**

---

## 1. Understanding Control and Managed Nodes

### Control Node:
The control node is the machine from which you run your Ansible commands and playbooks. This machine needs to have Ansible installed.

### Managed Nodes:
These are the systems that are being managed by the control node. Managed nodes only require SSH access, and no Ansible installation is necessary.

---

## 2. Preparing the Environment

Before installing Ansible, we need to ensure that the control and managed nodes can communicate with each other via SSH. In this example, we'll configure two nodes:
- **Control Node**: `pod-controller` (IP: `10.10.10.1`)
- **Managed Node**: `pod-managed1` (IP: `10.10.10.2`)

### Step 1: Setting Up the Hosts File

To make it easier for the control and managed nodes to communicate using hostnames, edit the `/etc/hosts` file on both nodes.

#### On the Control Node (`pod-controller`):
```bash
root@podX-controller:~# nano /etc/hosts
```

Add the following lines to define the IP addresses and hostnames of the control and managed nodes:
```
10.10.10.1 pod-controller
10.10.10.2 pod-managed1
```

#### On the Managed Node (`pod-managed1`):
```bash
root@podX-managed1:~# nano /etc/hosts
```

Similarly, add the same entries:
```
10.10.10.1 pod-controller
10.10.10.2 pod-managed1
```

### Step 2: Testing Connectivity Between Nodes

After updating the `/etc/hosts` file, test connectivity between the control and managed nodes by using the `ping` command.

#### On the Control Node:
```bash
root@podX-controller:~# ping -c 2 pod-controller
root@podX-controller:~# ping -c 2 pod-managed1
```

#### On the Managed Node:
```bash
root@podX-managed1:~# ping -c 2 pod-controller
root@podX-managed1:~# ping -c 2 pod-managed1
```

This ensures that both nodes can communicate with each other via hostnames.

### Step 3: Configuring SSH Key-Based Authentication

SSH key-based authentication allows secure, passwordless access between the control node and the managed nodes, which is essential for Ansible to function properly.

#### Step 3.1: Generate SSH Keys on Both Nodes

Generate an SSH key pair on both the control and managed nodes using the following command:

```bash
root@podX-controller:~# ssh-keygen -t rsa
root@podX-managed1:~# ssh-keygen -t rsa
```

This will generate a key pair (`id_rsa` and `id_rsa.pub`) in the `~/.ssh/` directory.

#### Step 3.2: Copy SSH Keys Between Nodes

Now, copy the public SSH keys to each node to enable key-based authentication.

**From the Control Node (`pod-controller`):**
```bash
root@podX-controller:~# ssh-copy-id -i ~/.ssh/id_rsa.pub student@pod-controller
root@podX-controller:~# ssh-copy-id -i ~/.ssh/id_rsa.pub student@pod-managed1
```

**From the Managed Node (`pod-managed1`):**
```bash
root@podX-managed1:~# ssh-copy-id -i ~/.ssh/id_rsa.pub student@pod-controller
root@podX-managed1:~# ssh-copy-id -i ~/.ssh/id_rsa.pub student@pod-managed1
```

### Step 4: Testing SSH Connection

Now, test if the SSH connection works properly using the `whoami` and `hostname` commands over SSH.

#### From the Control Node:
```bash
root@podX-controller:~# ssh student@pod-controller "whoami; hostname"
root@podX-controller:~# ssh student@pod-managed1 "whoami; hostname"
```

#### From the Managed Node:
```bash
root@podX-managed1:~# ssh student@pod-controller "whoami; hostname"
root@podX-managed1:~# ssh student@pod-managed1 "whoami; hostname"
```

If everything is set up correctly, the output should display the correct user (`student`) and hostname for each machine.

---

## 3. Installing Ansible on the Control Node

Next, we will install Ansible on the control node. This is the node from which all Ansible commands will be executed.

### Step 1: Install Required Dependencies

Update the package manager and install necessary packages:
```bash
root@podX-controller:~# sudo apt install software-properties-common
```

### Step 2: Add Ansible PPA Repository

Add the Ansible Personal Package Archive (PPA) to your control node’s repository list:
```bash
root@podX-controller:~# sudo add-apt-repository --yes --update ppa:ansible/ansible
```

### Step 3: Install Ansible

Update the package list and install Ansible:
```bash
root@podX-controller:~# sudo apt update
root@podX-controller:~# sudo apt install ansible
```

### Step 4: Verify the Installation

After the installation is complete, check the Ansible version to verify it’s installed correctly:
```bash
root@podX-controller:~# ansible --version
```

---

## 4. Configuring Ansible Inventory

The inventory file in Ansible defines the hosts and groups of hosts that Ansible will manage. By default, this file is located at `/etc/ansible/hosts`.

### Step 1: Create the Inventory File

Create and edit the inventory file on the control node:

```bash
root@podX-controller:~# sudo mkdir -p /etc/ansible
root@podX-controller:~# sudo vi /etc/ansible/hosts
```

### Step 2: Add Managed Nodes to the Inventory

In the `/etc/ansible/hosts` file, define the managed nodes. You can also group them under specific categories like `webservers`, `databases`, etc.

**Example Inventory File:**
```ini
pod-managed1

[webservers]
pod-managed2
```

This configuration defines `pod-managed1` as a general host and `pod-managed2` as part of the `webservers` group.

---

## 5. Testing the Setup

Now that Ansible is installed and configured, let's test the setup by running an Ansible command to ping the managed nodes.

### Step 1: List All Hosts

Run the following command to list all the hosts in your inventory:
```bash
root@podX-controller:~# ansible all --list-hosts
```

The output should display the hosts defined in the `/etc/ansible/hosts` file.

### Step 2: Ping All Hosts

Ping all the managed nodes to check if Ansible can communicate with them:
```bash
root@podX-controller:~# ansible all -m ping
```

If everything is set up correctly, the output should return a `pong` response from each managed node.

---

## 6. Summary

Congratulations! You’ve successfully set up Ansible on a control node and configured SSH-based communication with managed nodes. Here’s a recap of what you’ve accomplished:
1. Configured the `/etc/hosts` file for name resolution between the control and managed nodes.
2. Set up SSH key-based authentication to allow passwordless login between nodes.
3. Installed Ansible on the control node.
4. Configured the Ansible inventory to define managed nodes.
5. Verified connectivity and communication using the `ping` module in Ansible.

This environment is now ready for automation, configuration management, and orchestration using Ansible playbooks. In the next steps, you can start creating playbooks, defining tasks, and managing your infrastructure effortlessly!
